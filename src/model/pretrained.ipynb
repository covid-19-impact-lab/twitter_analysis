{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to root directory of project\n",
    "import os\n",
    "os.chdir('/home/tm/sciebo/corona/twitter_analysis/')\n",
    "\n",
    "from bld.project_paths import project_paths_join as ppj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "#import requests\n",
    "#import json\n",
    "#import argparse\n",
    "\n",
    "#from google.cloud import language\n",
    "#from google.oauth2 import service_account\n",
    "#from google.cloud.language import enums\n",
    "#from google.cloud.language import types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    ppj(\"IN_DATA\", \"training_data/data_clean_translated.csv\")\n",
    ").iloc[:, 1:]\n",
    "\n",
    "data_processed = pd.read_csv(\n",
    "    ppj(\"IN_DATA\", \"training_data/data_processed_translated.csv\"),\n",
    ").iloc[:, 1:]\n",
    "\n",
    "df = data.copy()\n",
    "\n",
    "df[\"processed\"] = data_processed.text\n",
    "\n",
    "df['sentiment_score'] = df.sentiment.replace({'neutral': 0, 'negative': -1, 'positive': 1})\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentiment(list_of_text, method):\n",
    "    \"\"\"Classify sentiment for each item in ``list_of_text``.\n",
    "    \n",
    "    Args:\n",
    "        list_of_text (list): List of strings for which the sentiment\n",
    "            should be classified.\n",
    "        \n",
    "        method (str): Name of method that should be used. Possible\n",
    "            values are 'google', 'vader', 'textblob'.\n",
    "            \n",
    "    Returns:\n",
    "        sentiments (list): List of respective sentiment score\n",
    "            for each item in ``list_of_text``.\n",
    "    \n",
    "    \"\"\"\n",
    "    analyzer = return_sentiment_analyzer(method)\n",
    "    \n",
    "    sentiments = analyzer(list_of_text)\n",
    "    return sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_sentiment_analyzer(method):\n",
    "    \"\"\"Return specific sentiment analyzer function.\n",
    "    \n",
    "    Args:\n",
    "        method (str): Name of method that should be used. Possible\n",
    "            values are 'google', 'vader', 'textblob'.\n",
    "            \n",
    "    Returns:\n",
    "        analyzer (function): Function which return a sentiment score\n",
    "            given text input. Inner workings depend on ``method``.\n",
    "        \n",
    "    \"\"\"\n",
    "    functions = {\n",
    "        'google': analyze_google,\n",
    "        'textblob': analyze_textblob,\n",
    "        'vader': analyze_vader,\n",
    "    }\n",
    "    \n",
    "    analyzer = functions[method]\n",
    "    return analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_google(list_of_text):\n",
    "    \"\"\"Return sentiment for each text in ``list_of_text``.\n",
    "    \n",
    "    Sentiments are analyzed using googles cloud natural language\n",
    "    api.\n",
    "    \n",
    "    Args:\n",
    "        list_of_text (list): List of strings for which the sentiment\n",
    "            should be classified.\n",
    "            \n",
    "    Returns:\n",
    "        sentiments (list): List of respective sentiment score\n",
    "            for each item in ``list_of_text``, where the sentiment score\n",
    "            is computed using google cloud natural language.\n",
    "            \n",
    "    \"\"\"\n",
    "    client = language.LanguageServiceClient.from_service_account_json(\n",
    "        'src/keys/ose-twitter-analysis-8508806b2efb.json'\n",
    "    )\n",
    "    \n",
    "    sentiments = []\n",
    "    for text in list_of_text:\n",
    "        document = types.Document(\n",
    "            content=text,\n",
    "            type=enums.Document.Type.PLAIN_TEXT\n",
    "        )\n",
    "        annotations = client.analyze_sentiment(document=document)\n",
    "        sentiments.append(annotations.document_sentiment.score)\n",
    "        \n",
    "    return sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_textblob(list_of_text):\n",
    "    \"\"\"Return sentiment for each text in ``list_of_text`` using ``textblob``.\n",
    "    \n",
    "    Args:\n",
    "        list_of_text (list): List of strings for which the sentiment\n",
    "            should be classified.\n",
    "            \n",
    "    Returns:\n",
    "        sentiments (list): List of respective sentiment score\n",
    "            for each item in ``list_of_text``, where the sentiment score\n",
    "            is computed using the package ``textblob``.\n",
    "            \n",
    "    \"\"\"\n",
    "    sentiments = [\n",
    "        TextBlob(text).sentiment.polarity for text in list_of_text\n",
    "    ]\n",
    "    return sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_vader(list_of_text):\n",
    "    \"\"\"Return sentiment for each text in ``list_of_text`` using ``vaderSentiment``.\n",
    "    \n",
    "    Args:\n",
    "        list_of_text (list): List of strings for which the sentiment\n",
    "            should be classified.\n",
    "            \n",
    "    Returns:\n",
    "        sentiments (list): List of respective sentiment score\n",
    "            for each item in ``list_of_text``, where the sentiment score\n",
    "            is computed using the package ``vaderSentiment``.\n",
    "            \n",
    "    \"\"\"\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    sentiments = [\n",
    "        analyzer.polarity_scores(text)['compound'] for text in list_of_text\n",
    "    ]\n",
    "    return sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzers = ['textblob', 'vader'] #, 'google']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['text', 'processed']:        \n",
    "    for m in analyzers:\n",
    "        df[m + \"_\" + col] = classify_sentiment(df[col].to_list(), method=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continuous_to_class(score):\n",
    "    new_score = np.zeros(score.shape)\n",
    "    \n",
    "    new_score[score < -0.33] = -1\n",
    "    new_score[score > 0.33] = 1\n",
    "    \n",
    "    new_score = pd.Series(new_score).replace(\n",
    "        {-1: 'negative', 0: 'neutral', 1: 'positive'}\n",
    "    )\n",
    "    return new_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_to_readable(cmat, labels):\n",
    "    columns = ['pred_' + lab for lab in labels]\n",
    "    rows = ['true_' + lab for lab in labels]\n",
    "    \n",
    "    df = pd.DataFrame(cmat, columns=columns, index=rows)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absolute_to_freq(cmat):\n",
    "    total = cmat.sum(axis=1)\n",
    "    return cmat / total[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le = le.fit(df[\"sentiment\"])\n",
    "y_true = le.transform(df[\"sentiment\"])\n",
    "\n",
    "columns = [\n",
    "    'textblob_text', \n",
    "    'vader_text', \n",
    "    'textblob_processed', \n",
    "    'vader_processed'\n",
    "]\n",
    "\n",
    "predictions = [\n",
    "    le.transform(continuous_to_class(df[col])) for col in columns\n",
    "]\n",
    "\n",
    "cmats = [\n",
    "    confusion_matrix(y_true, pred) for pred in predictions\n",
    "]\n",
    "\n",
    "cmats_freq = [absolute_to_freq(cmat) for cmat in cmats]\n",
    "\n",
    "df_cmats = [\n",
    "    confusion_matrix_to_readable(cmat, le.classes_) for cmat in cmats_freq\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.148318\n",
       "1    0.626758\n",
       "2    0.224924\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = pd.Series(y_true).value_counts() / len(y_true)\n",
    "weights = weights.reindex(le.transform(['negative', 'neutral', 'positive']))\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textblob_text\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_negative</th>\n",
       "      <th>pred_neutral</th>\n",
       "      <th>pred_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>true_negative</td>\n",
       "      <td>0.203093</td>\n",
       "      <td>0.695876</td>\n",
       "      <td>0.101031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>true_neutral</td>\n",
       "      <td>0.036838</td>\n",
       "      <td>0.793120</td>\n",
       "      <td>0.170041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>true_positive</td>\n",
       "      <td>0.020394</td>\n",
       "      <td>0.532291</td>\n",
       "      <td>0.447315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred_negative  pred_neutral  pred_positive\n",
       "true_negative       0.203093      0.695876       0.101031\n",
       "true_neutral        0.036838      0.793120       0.170041\n",
       "true_positive       0.020394      0.532291       0.447315"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent correctly classified: 0.62782874617737\n",
      "vader_text\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_negative</th>\n",
       "      <th>pred_neutral</th>\n",
       "      <th>pred_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>true_negative</td>\n",
       "      <td>0.411340</td>\n",
       "      <td>0.411340</td>\n",
       "      <td>0.177320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>true_neutral</td>\n",
       "      <td>0.159063</td>\n",
       "      <td>0.529397</td>\n",
       "      <td>0.311539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>true_positive</td>\n",
       "      <td>0.055744</td>\n",
       "      <td>0.286200</td>\n",
       "      <td>0.658056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred_negative  pred_neutral  pred_positive\n",
       "true_negative       0.411340      0.411340       0.177320\n",
       "true_neutral        0.159063      0.529397       0.311539\n",
       "true_positive       0.055744      0.286200       0.658056"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent correctly classified: 0.5408256880733945\n",
      "textblob_processed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_negative</th>\n",
       "      <th>pred_neutral</th>\n",
       "      <th>pred_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>true_negative</td>\n",
       "      <td>0.132990</td>\n",
       "      <td>0.740206</td>\n",
       "      <td>0.126804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>true_neutral</td>\n",
       "      <td>0.034155</td>\n",
       "      <td>0.807758</td>\n",
       "      <td>0.158087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>true_positive</td>\n",
       "      <td>0.027872</td>\n",
       "      <td>0.677090</td>\n",
       "      <td>0.295037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred_negative  pred_neutral  pred_positive\n",
       "true_negative       0.132990      0.740206       0.126804\n",
       "true_neutral        0.034155      0.807758       0.158087\n",
       "true_positive       0.027872      0.677090       0.295037"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent correctly classified: 0.5923547400611621\n",
      "vader_processed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_negative</th>\n",
       "      <th>pred_neutral</th>\n",
       "      <th>pred_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>true_negative</td>\n",
       "      <td>0.301031</td>\n",
       "      <td>0.532990</td>\n",
       "      <td>0.165979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>true_neutral</td>\n",
       "      <td>0.134911</td>\n",
       "      <td>0.593071</td>\n",
       "      <td>0.272018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>true_positive</td>\n",
       "      <td>0.056424</td>\n",
       "      <td>0.497621</td>\n",
       "      <td>0.445955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred_negative  pred_neutral  pred_positive\n",
       "true_negative       0.301031      0.532990       0.165979\n",
       "true_neutral        0.134911      0.593071       0.272018\n",
       "true_positive       0.056424      0.497621       0.445955"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent correctly classified: 0.5166666666666666\n"
     ]
    }
   ],
   "source": [
    "for col, df_tmp in zip(columns, df_cmats):\n",
    "    print(col)\n",
    "    display(df_tmp)\n",
    "    print(f\"Percent correctly classified: {df_tmp.values.diagonal().dot(weights)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter_analysis",
   "language": "python",
   "name": "twitter_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
